[zz1749@login-1-1 ~]$ hadoop jar /opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop-mapreduce/hadoop-streaming.jar -D mapreduce.job.reduces=1 -files myHW/HW3/HW3_map.py,myHW/HW3/HW3_reduce.py -mapper "python HW3_map.py" -reducer "python HW3_reduce.py" -input hdfs://dumbo/user/zz1749/class3/HW3.txt -output hdfs://dumbo/user/zz1749/class3/output
packageJobJar: [] [/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/jars/hadoop-streaming-2.6.0-cdh5.11.1.jar] /tmp/streamjob3008964855477697011.jar tmpDir=null
18/06/18 00:03:35 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/18 00:03:35 INFO mapreduce.JobSubmitter: number of splits:2
18/06/18 00:03:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1528077494936_1205
18/06/18 00:03:36 INFO impl.YarnClientImpl: Submitted application application_1528077494936_1205
18/06/18 00:03:36 INFO mapreduce.Job: The url to track the job: http://babar.es.its.nyu.edu:8088/proxy/application_1528077494936_1205/
18/06/18 00:03:36 INFO mapreduce.Job: Running job: job_1528077494936_1205
18/06/18 00:04:30 INFO mapreduce.Job: Job job_1528077494936_1205 running in uber mode : false
18/06/18 00:04:30 INFO mapreduce.Job:  map 0% reduce 0%
18/06/18 00:04:34 INFO mapreduce.Job:  map 100% reduce 0%
18/06/18 00:04:39 INFO mapreduce.Job:  map 100% reduce 100%
18/06/18 00:04:40 INFO mapreduce.Job: Job job_1528077494936_1205 completed successfully
18/06/18 00:04:40 INFO mapreduce.Job: Counters: 53
        File System Counters
                FILE: Number of bytes read=132
                FILE: Number of bytes written=406426
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=325
                HDFS: Number of bytes written=102
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=17176
                Total time spent by all reduces in occupied slots (ms)=13020
                Total time spent by all map tasks (ms)=4294
                Total time spent by all reduce tasks (ms)=2170
                Total vcore-milliseconds taken by all map tasks=4294
                Total vcore-milliseconds taken by all reduce tasks=2170
                Total megabyte-milliseconds taken by all map tasks=17588224
                Total megabyte-milliseconds taken by all reduce tasks=13332480
        Map-Reduce Framework
                Map input records=6
                Map output records=15
                Map output bytes=210
                Map output materialized bytes=167
                Input split bytes=182
                Combine input records=0
                Combine output records=0
                Reduce input groups=15
                Reduce shuffle bytes=167
                Reduce input records=15
                Reduce output records=6
                Spilled Records=30
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=141
                CPU time spent (ms)=2290
                Physical memory (bytes) snapshot=1432371200
                Virtual memory (bytes) snapshot=11194408960
                Total committed heap usage (bytes)=3598188544
                Peak Map Physical memory (bytes)=542302208
                Peak Map Virtual memory (bytes)=3731304448
                Peak Reduce Physical memory (bytes)=350744576
                Peak Reduce Virtual memory (bytes)=3736883200
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=143
        File Output Format Counters
                Bytes Written=102
18/06/18 00:04:40 INFO streaming.StreamJob: Output directory: hdfs://dumbo/user/zz1749/class3/output
[zz1749@login-1-1 ~]$ hdfs dfs -cat class3/output/part-00000
A C F 0.116667
C A B 0.200001
B D E F 0.200001
E F 0.088889
D A B C E F 0.055556
F B C 0.338890
[zz1749@login-1-1 ~]$