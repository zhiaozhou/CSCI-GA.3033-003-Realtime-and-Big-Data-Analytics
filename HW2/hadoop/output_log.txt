[zz1749@login-2-1 hadoop]$ hadoop jar /opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop-mapreduce/hadoop-streaming.jar -D mapreduce.job.reduces=1 -files ./HW2_map.py,./HW2_reduce.py -mapper "HW2_map.py" -reducer "HW2_reduce.py" -input hdfs://dumbo/user/zz1749/class2/HW2.txt -output class2/output
packageJobJar: [] [/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/jars/hadoop-streaming-2.6.0-cdh5.11.1.jar] /tmp/streamjob8898585186574346500.jar tmpDir=null
18/06/05 21:20:08 INFO mapred.FileInputFormat: Total input paths to process : 1
18/06/05 21:20:08 INFO mapreduce.JobSubmitter: number of splits:2
18/06/05 21:20:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1528077494936_0113
18/06/05 21:20:09 INFO impl.YarnClientImpl: Submitted application application_1528077494936_0113
18/06/05 21:20:09 INFO mapreduce.Job: The url to track the job: http://babar.es.its.nyu.edu:8088/proxy/application_1528077494936_0113/
18/06/05 21:20:09 INFO mapreduce.Job: Running job: job_1528077494936_0113
18/06/05 21:20:13 INFO mapreduce.Job: Job job_1528077494936_0113 running in uber mode : false
18/06/05 21:20:13 INFO mapreduce.Job:  map 0% reduce 0%
18/06/05 21:20:17 INFO mapreduce.Job:  map 100% reduce 0%
18/06/05 21:20:22 INFO mapreduce.Job:  map 100% reduce 100%
18/06/05 21:20:23 INFO mapreduce.Job: Job job_1528077494936_0113 completed successfully
18/06/05 21:20:23 INFO mapreduce.Job: Counters: 53
        File System Counters
                FILE: Number of bytes read=91
                FILE: Number of bytes written=406359
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=616
                HDFS: Number of bytes written=39
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=16176
                Total time spent by all reduces in occupied slots (ms)=13392
                Total time spent by all map tasks (ms)=4044
                Total time spent by all reduce tasks (ms)=2232
                Total vcore-milliseconds taken by all map tasks=4044
                Total vcore-milliseconds taken by all reduce tasks=2232
                Total megabyte-milliseconds taken by all map tasks=16564224
                Total megabyte-milliseconds taken by all reduce tasks=13713408
        Map-Reduce Framework
                Map input records=3
                Map output records=12
                Map output bytes=117
                Map output materialized bytes=141
                Input split bytes=182
                Combine input records=0
                Combine output records=0
                Reduce input groups=7
                Reduce shuffle bytes=141
                Reduce input records=12
                Reduce output records=4
                Spilled Records=24
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=128
                CPU time spent (ms)=2280
                Physical memory (bytes) snapshot=1442004992
                Virtual memory (bytes) snapshot=11200602112
                Total committed heap usage (bytes)=3567779840
                Peak Map Physical memory (bytes)=542019584
                Peak Map Virtual memory (bytes)=3727548416
                Peak Reduce Physical memory (bytes)=358957056
                Peak Reduce Virtual memory (bytes)=3745808384
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=434
        File Output Format Counters
                Bytes Written=39
18/06/05 21:20:23 INFO streaming.StreamJob: Output directory: class2/output
[zz1749@login-2-1 hadoop]$ hdfs dfs -cat class2/output/part-00000
Dec 2
Java 0
hackathon 2
Chicago 1